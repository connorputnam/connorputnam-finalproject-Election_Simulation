---
title: "Lets simulate an election!"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(scales)
library(formattable)
```

Start by reading in the senate polling data. I have this as a .cvs so it will need to manually updated from time to time. 

```{r}
polls <- read.csv("senate_polls.csv")
```

```{r}
polls <- polls %>%
  filter(state == "Georgia") %>%
  filter(race_id == "7780" | race_id == "6271") %>%
  group_by(candidate_name)
polls
```

```{r}
EDA_polls <- polls %>% 
  group_by(candidate_name, candidate_party) %>%
  summarise(average_polling = mean(pct)) %>%
  filter(candidate_name == "Raphael Warnock" | candidate_name == "Kelly Loeffler" | candidate_name == "Doug Collins" |
         candidate_name == "Matthew Lieberman" | candidate_name == "Ed Tarver" | candidate_name == "Brian Richard Slowinski")

ggplot(EDA_polls, aes(reorder(candidate_name, average_polling), average_polling, fill = candidate_party, label = round(average_polling, 2))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values=c("#26b3f2", "#fcd407", "#ec1e26")) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ylab("Polling Average(percent)") +
  xlab("Candidate") +
  geom_text(position = position_dodge(width = .9),    # move to center of bars
              vjust = -.5,    # nudge above top of bar
              size = 3) +
  ylim(0, 25)
```


```{r}
EDA_polls_rating <- polls %>% 
  group_by(fte_grade) %>%
  count(fte_grade) %>%
  mutate(fte_grade = fct_recode(fte_grade, "No Rating" = ""))

#fct_recode 

ggplot(EDA_polls_rating, aes(fte_grade, n, fill = fte_grade)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ylab("Number of Polls Conducted") +
  xlab("Rating") +
  ggtitle("Counts per Pollster Rating") +
  labs(fill = "Ratings")
```
 
Now that the off happened...going to build the model based off of Perdue vs Ossoff and then make a function that can sub out either race

```{r}
Perdue_vs_Ossoff <- polls %>% 
  group_by(candidate_name, candidate_party) %>%
  summarise(average_polling = mean(pct)) %>%
  filter(candidate_name == "David A. Perdue" | candidate_name == "Jon Ossoff")
Perdue_vs_Ossoff

ggplot(Perdue_vs_Ossoff, aes(reorder(candidate_name, average_polling), average_polling, fill = candidate_party, label = round(average_polling, 2))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values=c("#26b3f2", "#ec1e26")) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ylab("Polling Average(percent)") +
  xlab("Candidate") +
  geom_text(position = position_dodge(width = .9),    # move to center of bars
              vjust = -.5,    # nudge above top of bar
             size = 3) 
  ylim(0, 60)
```

This is where some of my priors/judgement calls come into play. I am going to use data on previous elections, as well as the over partisan lean of Geogria, and some other factor.

```{r}
#bringing in old data

historical <- read.csv("us_senate_elections.csv")
historical <- historical %>%
  filter(state == "GA" |state == "Georgia") # just geogria

average_historical <- function(select_year){
  historical %>% 
  filter(year == select_year) %>%
  filter(office == "Senate") %>%
  group_by(candidate, year, party) %>%
  summarise(average_polling = mean(projected_voteshare), actutal_voteshare = mean(actual_voteshare))
}

#Isakson vs Barksdale
summary_table <- bind_rows(average_historical("2016"), average_historical("2014"))

formattable(summary_table,
            align = c("l", rep("r", rep(NCOL(summary_table)))),
            list(`"Summary Statistics"` = formatter("span",
                              style = ~style(color = "gray"))))
            
```


