---
title: "Lets simulate an election!"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(scales)
library(formattable)
library(SuppDists)
library(reshape2)
```

Start by reading in the senate polling data. I have this as a .cvs so it will need to manually updated from time to time. 

```{r}
polls <- read.csv("senate_polls.csv")
```

```{r}
polls <- polls %>%
  filter(state == "Georgia") %>%
  filter(race_id == "7780" | race_id == "6271") %>%
  group_by(candidate_name)
polls
```

# EDA

```{r}
EDA_polls <- polls %>% 
  group_by(candidate_name, candidate_party) %>%
  summarise(average_polling = mean(pct)) %>%
  filter(candidate_name == "Raphael Warnock" | candidate_name == "Kelly Loeffler" | candidate_name == "Doug Collins" |
         candidate_name == "Matthew Lieberman" | candidate_name == "Ed Tarver" | candidate_name == "Brian Richard Slowinski")

ggplot(EDA_polls, aes(reorder(candidate_name, average_polling), average_polling, fill = candidate_party, label = round(average_polling, 2))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values=c("#26b3f2", "#fcd407", "#ec1e26")) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ylab("Polling Average(percent)") +
  xlab("Candidate") +
  geom_text(position = position_dodge(width = .9),    # move to center of bars
              vjust = -.5,    # nudge above top of bar
              size = 3) +
  ylim(0, 25)
```


```{r}
EDA_polls_rating <- polls %>% 
  group_by(fte_grade) %>%
  count(fte_grade) %>%
  mutate(fte_grade = fct_recode(fte_grade, "No Rating" = ""))

#fct_recode 

ggplot(EDA_polls_rating, aes(fte_grade, n, fill = fte_grade)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ylab("Number of Polls Conducted") +
  xlab("Rating") +
  ggtitle("Counts per Pollster Rating") +
  labs(fill = "Ratings")
```
 
Now that the off happened...going to build the model based off of Perdue vs Ossoff and then make a function that can sub out either race

```{r}
Perdue_vs_Ossoff <- polls %>% 
  group_by(candidate_name, candidate_party, cycle) %>%
  mutate(standard_deviation = sd(pct)) %>%
  summarise(average_polling = mean(pct), standard_deviation = mean(standard_deviation)) %>%
  filter(candidate_name == "David A. Perdue" | candidate_name == "Jon Ossoff")
Perdue_vs_Ossoff


ggplot(Perdue_vs_Ossoff, aes(reorder(candidate_name, average_polling), average_polling, fill = candidate_party, label = round(average_polling, 2))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values=c("#26b3f2", "#ec1e26")) +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  ylab("Polling Average(percent)") +
  xlab("Candidate") +
  geom_text(position = position_dodge(width = .9),    # move to center of bars
              vjust = -.5,    # nudge above top of bar
             size = 3) 
  ylim(0, 60)
```

This is where some of my priors/judgement calls come into play. I am going to use data on previous elections, as well as the over partisan lean of Geogria, and some other factor.

```{r}
#bringing in old data

historical <- read.csv("us_senate_elections.csv")
historical <- historical %>%
  filter(state == "GA" |state == "Georgia") # just geogria

average_historical <- function(select_year){
  historical %>% 
  filter(year == select_year) %>%
  filter(office == "Senate") %>%
  group_by(candidate, year, party) %>%
  summarise(average_polling = mean(projected_voteshare), actutal_voteshare = mean(actual_voteshare),
            standard_deviation = mean(sd(projected_voteshare))) 
            #standard_deviation_actual = mean(sd(actual_voteshare)))
}

#Isakson vs Barksdale and Perdue vs Nunn
summary_table <- bind_rows(average_historical("2016"), average_historical("2014"))

#formattable(summary_table,
        #    align = c("l", rep("r", rep(NCOL(summary_table)))),
        #    list(`"Summary Statistics"` = formatter("span",
            #                  style = ~style(color = "gray"))))
```

# Historical Data
```{r}
Perdue_vs_Ossoff
summary_table <- summary_table %>%
  rename("candidate_party" = party) %>%
  rename("cycle" = year) %>%
  rename("candidate_name" = candidate)
```

```{r}
total_data <- bind_rows(Perdue_vs_Ossoff, summary_table) %>%
  mutate(candidate_party = recode(candidate_party, 
                                  `REP` = "R", 
                                  `DEM` = "D")) %>%
  filter(candidate_party == "R" | candidate_party == "D") %>% #2020 election will not have independents, only top two advance
  group_by(cycle) %>%
  arrange(cycle, candidate_party) %>%
  mutate(spread = average_polling - lag(average_polling)) %>%
  fill(spread, .direction = "up") %>%
  mutate(spread = case_when(candidate_party == "R" ~ spread,
                            candidate_party == "D" ~ (-1 * spread))) #creating the spread for both candidates based on party. THis took be a longggg time to figure out
  #pivot_longer(cols = c(candidate_name, average_polling, standard_deviation), names_to = "variables", values_to = "times")
total_data
```

# Johnson vs Normal

```{r}
n <- 100000
parmamter_data <- polls %>% 
  group_by(candidate_name) %>%
  select(candidate_name, pct) %>%
  filter(candidate_name == "David A. Perdue" | candidate_name == "Jon Ossoff")
paramters <- JohnsonFit(parmamter_data$pct)

johnson_dist <- rJohnson(n = n, 
                         parms = list(gamma = 0, 
                                      delta = .5, 
                                      xi = 0, #no really sure what this parameter is doing...
                                      lambda = 2, 
                                      type = "SN"))

normal_dist <- rnorm(n = n, mean = 0, sd = 1)

overlay <- melt(as.data.frame(cbind(johnson_dist, normal_dist)))

ggplot(overlay, aes(value, fill = variable)) +
  geom_density(alpha = 0.5)
#fat tails!
```

```{r}
## Set up for computing the distributions of spreads in regards to jon ossoff

empty_vec <- rep((total_data %>% filter(cycle == "2020") %>% filter(candidate_name == "David A. Perdue"))$spread , 100)
#perdue is in two races....casuing headaches here
ossof_probs <- (sd(johnson_dist) * johnson_dist) + empty_vec

ggplot(data.frame(ossof_probs), aes(x = ossof_probs)) +
  geom_density() +
  geom_vline(xintercept = mean(ossof_probs))

win <- length(which(ossof_probs > 0)) / n #prob  winning
lose <- length(which(ossof_probs < 0)) / n #prob  losing

cbind(win, lose)
```

- meaning democrate closes by that much, and positive means wins by that much




# Bootstrapping

```{r}
boot_polls <- polls %>% 
  group_by(candidate_name, candidate_party, cycle) %>%
  #mutate(standard_deviation = sd(pct)) %>%
  #mutate(average_polling = mean(pct), standard_deviation = mean(standard_deviation)) %>%
  filter(candidate_name == "David A. Perdue" | candidate_name == "Jon Ossoff")

boot_data <- boot_polls %>%
  mutate(candidate_party = recode(candidate_party, 
                                  `REP` = "R", 
                                  `DEM` = "D")) %>%
  filter(candidate_party == "R" | candidate_party == "D") %>% #2020 election will not have independents, only top two advance
  group_by(question_id) %>%
  #arrange(question_id, candidate_party) %>%
  select(question_id, poll_id, fte_grade, sample_size, candidate_name, candidate_party, pct) %>%
  filter(question_id != 123442 & question_id != 123443) %>%
  mutate(spread = pct - pct[candidate_party == "D"]) %>%
  mutate(spread2 = pct - pct[candidate_party == "R"]) %>%
  mutate(actual_spread = spread + spread2) %>%
  select(-spread, -spread2)
boot_data
```

```{r}
ggplot(boot_data, aes(actual_spread)) +
  geom_histogram(bins = 15)
```

```{r}
boot_spread <- map(1:10000, ~sample(boot_data$actual_spread, size = length(boot_data), replace = TRUE)) %>%
  map_dbl(mean)

boot_spread <- melt(boot_spread)
ggplot(boot_spread, aes(value)) +
  geom_histogram(aes(y=..density..)) +
  stat_function(fun = dnorm, args = c(mean = mean(boot_spread$value), sd = sd(boot_spread$value))) +
  geom_vline(xintercept = mean(boot_spread$value))
```




